# COMPLEJIDAD ALGORITMICA
La complejidad algorítmica es una medida que permite analizar el rendimiento de un algoritmo en términos de los recursos que utiliza, principalmente el tiempo de ejecución (complejidad temporal) y la memoria (complejidad espacial), en función del tamaño de la entrada. Su propósito es ayudar a comparar algoritmos para una misma tarea, identificando cuál es más eficiente a medida que los datos de entrada aumentan, de modo que se busca optimizar los recursos para maximizar el rendimiento, logrando un menor costo y mayores beneficios. Este enfoque tiene una visión empresarial, buscando un uso eficiente de los recursos disponibles.

Los recursos consumidos son:
- Tiempo de ejecución.
- Memoria principal.
- Entradas/salidas a disco.
- Comunicaciones, procesadores, etc.

Los recursos dependen de:
- El tipo de procesador donde ejecuta el programa. Es decir, la naturaleza y rapidez de las instrucciones máquina del procesador concreto.
- El lenguaje de programación y la calidad del código que genera el compilador.
- La complejidad intrínseca del algoritmo: la implementación que haga el programador del algoritmo. En particular, de las estructuras de datos utilizadas.
- Datos de entrada: su tamaño y contenido.
- Factores externos.

Y los resultados son:
- Resolver un problema de forma exacta.
- Mantener la eficacia en el tiempo.
- Ajustarlo a los cambios del contexto.

> [!IMPORTANT]
> Aunque ambos términos pueden considerarse sinónimos, la complejidad algoritmica se centra más en el software, mientras que la complejidad computacional tiene en cuenta el hardware. 

Es así que la eficiencia de un algoritmo se determina en función de cómo maneja el tiempo y espacio de memoria necesarios para completar una tarea. En resumen, un algoritmo será "más eficiente" comparado con otro cuando utilice menos recursos, espacio memoria y tiempo. La eficacia del algoritmo es esencial, ya que un algoritmo ineficaz no es útil y se busca que dicha eficacia se mantenga en el tiempo. Por otro lado, la eficiencia siempre es comparativa, lo que implica medirla contra otros algoritmos similares. La eficiencia total es una utopía, ya que siempre habrá un margen de mejora.

## SIMPLICIDAD & LEGIBILIDAD
La simplicidad de un algoritmo facilita su verificación, el análisis de su eficiencia y su mantenimiento. Esto significa que un código más legible y directo es preferible sobre alternativas complejas y difíciles de interpretar. La simplicidad contribuye a que el código sea más comprensible, reducible a partes fácilmente verificables y mantenible a lo largo del tiempo. Básicamente, se puede resumir todo esto en simplemente "No buscarle la quinta pata al gato".

> [!TIP]
> Ejemplos:
> - Para listas: utilizar iteración en lugar de recursividad, ya que la estructura secuencial de las listas se adapta mejor al procesamiento repetitivo con ciclos.
> - Para árboles: usar recursividad en lugar de iteración. En estructuras jerárquicas como los árboles, es preferible el uso de recursividad, dado que permite un recorrido natural (inorden, preorden, postorden) y simplifica el manejo de subestructuras.
> - Para arreglos: recorrer usando el ciclo manejado por contador y no otros. Este ciclo manejado por contador permite un acceso directo por índice y optimiza la legibilidad y la eficiencia del código.
> - Legibilidad: Nombres de variables útiles y comentarios adecuados.
> - Comentarios detallados (no ocupan memoria y ayudan a comprender el código).
> - Seguir convenciones (empresariales o estándar) para nombres y abreviaturas. Esto facilita la lectura, evita ambigüedades y mejora la coherencia del proyecto.

# Complejidad Espacial
El tipo de estructura de datos influye directamente en la complejidad del algoritmo. Por ejemplo, en estructuras almacenadas en memoria interna, el tamaño es relevante. Por ello es que, si trabajamos con arreglos, es posible predecir el espacio que ocuparán, pero esto no ocurre tan fácilmente con listas o árboles. Asimismo, el diseño del algoritmo depende del contexto. Por ejemplo, si se realiza un recorrido en un arreglo, es preferible usar un contador, ya que otras estrategias son innecesarias y menos eficientes.

Se refiere a la cantidad de memoria que el algoritmo necesita para ejecutarse. Esta memoria puede ser:
   - **Estática:** cuando se calcula a partir del espacio ocupado por las variables declaradas en el código, sin depender de la ejecución. Es el mínimo espacio necesario.
   - **Dinámica:** que varía en cada ejecución, dependiendo de factores como la cantidad de datos de entrada.  Depende de la ejecución y puede ser incierta (salvo en estructuras como árboles con un tamaño máximo definido).

> [!NOTE]
> La eficiencia en memoria de un algoritmo se mide por la cantidad de espacio requerido para ejecutar el algoritmo.

# Complejidad Temporal 
El tiempo de ejecución es una predicción teórica, no un valor medido directamente durante la ejecución. Esto significa que es un "tiempo" a considerar con precaución, ya que se evalúa sin considerar las características específicas de cada hardware. Se refiere al tiempo de ejecución o tiempo de cómputo necesario para que el algoritmo complete su tarea. Para medir esta complejidad, se identifica una medida $$\ n \$$, que generalmente representa el tamaño de la entrada o el número de datos que el algoritmo debe procesar. Luego, se intenta expresar el tiempo de ejecución en función de $$\ n \$$ lo cual permite comparar el comportamiento de distintos algoritmos para problemas similares a medida que $$\ n \$$ crece.

## Estudio del tiempo de ejecución
- **Caso a priori:** proporciona una medida teórica, obteniendo una función que estime el tiempo de ejecución en función de $$\ n \$$. Esto se hace sin ejecutar el algoritmo, lo cual permite comparar algoritmos independientemente de la máquina utilizada. Resumiendo, se realiza antes de ejecutar el algoritmo, en papel y constituye una **estimación**.
- **Caso a posteriori:** consiste en medir el tiempo de ejecución real en una máquina específica, obteniendo resultados concretos para el rendimiento del algoritmo.
Ambas mediciones son complementarias: la primera permite prever el rendimiento en general, mientras que la segunda muestra el tiempo real en condiciones específicas. Depende del hardware usado y se mide el tiempo real. por lo que representa las medidas reales del comportamiento del algoritmo.

> [!IMPORTANT]
> El tiempo de ejecución en papel es abstracto. No se mide en segundos, minutos u otra unidad de tiempo convencional, sino que nos basamos en algo denominado como [operaciones elementales](1.%20Operaciones%20Elementales.md): el número de operaciones básicas ejecutadas, o mejor dicho, son aquellas operaciones que una computadora ejecuta en un tiempo acotado por una constante.

Casos de complejidad temporal
- **Caso mejor:** la traza (secuencia de sentencias) del algoritmo realiza el menor número de acciones posible. Por ejemplo, encontrar un elemento que buscamos en la primer posición del arreglo.
- **Caso peor:** la traza del algoritmo realiza el mayor número de instrucciones. Por ejemplo, realizar una búsqueda y encontrar el elemento en la última posición de un arreglo, o directamente no encontrarlo.
- **Caso medio:** el número de instrucciones se basa en el promedio esperado sobre todas las trazas posibles del algoritmo para un tamaño de entrada dado. Se calcula un promedio entre el mejor y el peor caso, ya que su diferencia es mínima.

$$
I_{\text{medio}}(n) = \frac{I_{\text{mejor}}(n) + I_{\text{peor}}(n)}{2}
$$

Obviamente, notese que, en casos como una búsqueda lineal pura, el mejor y el peor caso son equivalentes porque siempre recorre todo el arreglo.

> [!WARNING]
> Es importante destacar que el análisis de los casos mejor y peor se refiere a un tamaño de entrada específico, no a la cantidad de instrucciones para un valor concreto como $$\ n = 1 \$$. A menudo, se confunde el caso "mejor" como el que menos instrucciones realiza para un tamaño de entrada dado, lo cual puede llevar a errores de interpretación.

